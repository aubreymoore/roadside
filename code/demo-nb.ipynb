{
 "cells": [
  {
   "cell_type": "raw",
   "id": "pretty-bikini",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "Example usage:\n",
    "\n",
    "    cd ~/Guam02/code/object-detectors\n",
    "    source ~/Guam02/code/py38env/bin/activate\n",
    "    python3.6 demo.py --video /home/aubreytensor1/Guam02/rawdata/20201211_134207.mp4 --output_dir /home/aubreytensor1/Guam02/output --num_frames 5 --skip_no 1 --dump_sql False\n",
    "\n",
    "Mod by Aubrey Moore 2020-12-25: added else clause:\n",
    "\n",
    "    if width > 1920 or height > 1080:\n",
    "        image = image_org.resize((width // 2, height // 2), Image.ANTIALIAS)\n",
    "    else:\n",
    "        image = image_org\n",
    "\n",
    "Mod by Aubrey Moore 2020-12-25: added --output_dir argument\n",
    "\n",
    "Mod by Aubrey Moore 2021-01-15:\n",
    "    Added a kludge in get_polygons to handle a rare \"list index out of range error\" for contours[0]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "applied-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set environment variables\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# import tensorflow as tf\n",
    "# uncomment following lines if you are using TF2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import cv2\n",
    "import argparse\n",
    "from PIL import Image\n",
    "# from gpslogger import GPSLogger\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('./Mask_RCNN')\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "import skimage.io\n",
    "from collections import OrderedDict\n",
    "from skimage.measure import find_contours, approximate_polygon\n",
    "from xml_dumper import dump_as_cvat_annotation\n",
    "#from sql_dumper import dump_to_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-mixture",
   "metadata": {},
   "source": [
    "Run from roadside/code directory:\n",
    "\n",
    "    python3 demo.py --dump_sql False --video ../open-camera-test/20210430_094616.mp4 --skip_no 1 --output_dir ../open-camera-test/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quarterly-belly",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Run from the roadside/code directory:\n",
    "\n",
    "# papermill -p dump_sql False -p video '../open-camera-test/20210430_094616.mp4' -p skip_no 1 -p output_dir '../open-camera-test/output'\n",
    "\n",
    "type = 'both'                                                  # what type of models to use [both,classes,v_shape]\n",
    "video = 'inference_data/20200703_121802.mp4'                   # path to video\n",
    "gps_csv = 'inference_data/20200703_121802_gps.csv'             # path to csv containing gps data\n",
    "skip_no = 7                                                    # int, num of frames to skip (must be >0)\n",
    "num_frames = None                                              # how many frames to consider?\n",
    "od_model = \"inference_data/frozen_inference_graph_5classes.pb\" # path to trained detection model\n",
    "classes_cvat = \"inference_data/5classes.csv\"                   # classes you want to use for cvat, see readme for more details.\n",
    "classes_type = \"od\"                                            # type of classes csv file [od, maskrcnn]\n",
    "mask_model =  \"inference_data/mask_rcnn_cvat_0160.h5\"          # path to trained maskrcnn model\n",
    "od_threshold = 0.5                                             # threshold for IoU\n",
    "mask_threshold = 0.5                                           # threshold for maskrcnn\n",
    "output_video = \"output.mp4\"                                    # where to store output video\n",
    "survey_type = \"v_shape\"                                        # what to write in geojson [v_shape,classes]\n",
    "task_id = 0                                                    # required only if you want to use this in cvat\n",
    "task_name = \"demo\"                                             # required only if you want to use this in cvat\n",
    "write_into_objects = True                                      # should this enter detected objects into objects table?\n",
    "drop_extra_clm = True                                          # whether it should drop extra columns? required if dumping into objects table\n",
    "output_dir = ''                                                # output directory for video with objects detected and CVAT xml\n",
    "dump_sql = True\n",
    "\n",
    "# RESET\n",
    "\n",
    "# dump_sql = False \n",
    "# video = '../open-camera-test/20210430_094616.mp4' \n",
    "# skip_no = 1 \n",
    "# output_dir = '../open-camera-test/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alien-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "    def __init__(self, model_path):\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(model_path , 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "                config = tf.ConfigProto()\n",
    "                config.gpu_options.allow_growth=True\n",
    "                self.sess = tf.Session(graph=self.detection_graph, config=config)\n",
    "\n",
    "    def get_detections(self, image_np_expanded):\n",
    "        image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        (boxes, scores, classes, num_detections) = self.sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n",
    "        return boxes, scores, classes, num_detections\n",
    "\n",
    "    @staticmethod\n",
    "    def process_boxes(boxes, scores, classes, labels_mapping, threshold, width, height):\n",
    "        result = {}\n",
    "        for i in range(len(classes[0])):\n",
    "            if classes[0][i] in labels_mapping.keys():\n",
    "                if scores[0][i] >= threshold:\n",
    "                    xmin = int(boxes[0][i][1] * width)\n",
    "                    ymin = int(boxes[0][i][0] * height)\n",
    "                    xmax = int(boxes[0][i][3] * width)\n",
    "                    ymax = int(boxes[0][i][2] * height)\n",
    "                    label = labels_mapping[classes[0][i]]\n",
    "                    if label not in result:\n",
    "                        result[label] = []\n",
    "                    result[label].append([xmin,ymin,xmax,ymax])\n",
    "        return result\n",
    "\n",
    "class Segmentation:\n",
    "    def __init__(self, model_path, num_c=2):\n",
    "        class InferenceConfig(Config):\n",
    "            # Set batch size to 1 since we'll be running inference on\n",
    "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "            NAME = \"cvat\"\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "            NUM_CLASSES = num_c\n",
    "\n",
    "        config = InferenceConfig()\n",
    "        #config.display()\n",
    "\n",
    "        # Create model object in inference mode.\n",
    "        self.model = modellib.MaskRCNN(mode=\"inference\", model_dir=\"./output\", config=config)\n",
    "        # Load weights trained on MS-COCO\n",
    "        self.model.load_weights(model_path, by_name=True)\n",
    "        self.labels_mapping = {0:'BG', 1:'cut'}\n",
    "\n",
    "    def get_polygons(self, images, threshold):\n",
    "        res = self.model.detect(images)\n",
    "        result = {}\n",
    "        for r in res:\n",
    "            for index, c_id in enumerate(r['class_ids']):\n",
    "                if c_id in self.labels_mapping.keys():\n",
    "                    if r['scores'][index] >= threshold:\n",
    "                        mask = r['masks'][:,:,index].astype(np.uint8)\n",
    "                        contours = find_contours(mask, 0.5)\n",
    "\n",
    "                        # KLUDGE\n",
    "                        # Handles a rare \"list index out of range error\" for contours[0]\n",
    "                        # If the contours array is empty, a dummy contour consisting of\n",
    "                        # the top left pisxel is provided.\n",
    "\n",
    "                        if not contours:\n",
    "                            print('ERROR: contour list is empty.')\n",
    "                            contour = np.array([[1.0,1.0],[1.0,0.0],[0.0,0.0],[0.0,1.0],[1.0,1.0]])\n",
    "                        else:\n",
    "                            contour = contours[0]\n",
    "                            # print(f'contour ({type(contour)}): {contour}')\n",
    "\n",
    "                        # end of KLUDGE\n",
    "\n",
    "                        contour = np.flip(contour, axis=1)\n",
    "                        contour = approximate_polygon(contour, tolerance=2.5)\n",
    "                        segmentation = contour.ravel().tolist()\n",
    "                        label = self.labels_mapping[c_id]\n",
    "                        if label not in result:\n",
    "                            result[label] = []\n",
    "                        result[label].append(segmentation)\n",
    "        return result\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def process_polygons(polygons, boxes):\n",
    "        \"\"\"\n",
    "           Check if any point of the polygon falls into any of coconot palms except for dead/non_recoverable.\n",
    "        \"\"\"\n",
    "        def _check_inside_boxes(polygon, boxes):\n",
    "            for point in polygon:\n",
    "                for label, bxes in boxes.items():\n",
    "                    for box in bxes:\n",
    "                        if point[0] > box[0] and point[0] < box[2] and point[1] > box[1] and point[1] < box[3] and label not in ['dead','non_recoverable']:\n",
    "                            # point is inside rectangle\n",
    "                            return True\n",
    "            return False\n",
    "\n",
    "        result = {}\n",
    "        for label_m, polys in polygons.items():\n",
    "            for polygon in polys:\n",
    "                p = [polygon[i:i+2] for i in range(0, len(polygon),2)]\n",
    "                if _check_inside_boxes(p, boxes):\n",
    "                    if label_m not in result:\n",
    "                        result[label_m] = []\n",
    "                    result[label_m].append(polygon)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def load_image_into_numpy(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def draw_instances(frame, boxes, masks):\n",
    "    colors = {'zero':(0,255,0), 'light':(0,0,255),'medium':(255,0,0),'high':(120,120,0),'non_recoverable':(0,120,120),'cut':(0,0,0)}\n",
    "    #draw boxes\n",
    "    for label, bxes in boxes.items():\n",
    "        for box in bxes:\n",
    "            cv2.rectangle(frame, (box[0],box[1]), (box[2],box[3]), colors[label], 5)\n",
    "    #draw polygons\n",
    "    for label, polygons in masks.items():\n",
    "        for polygon in polygons:\n",
    "            p = [polygon[i:i+2] for i in range(0, len(polygon),2)]\n",
    "            pts = np.array(p, np.int32)\n",
    "            pts = pts.reshape((-1,1,2))\n",
    "            cv2.polylines(frame, [pts], True, (0,255,255),5)\n",
    "    return frame\n",
    "\n",
    "def get_labels(classes_csv, type=\"od\"):\n",
    "    labels = []\n",
    "    with open(classes_csv, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "        # slogger.glob.info(\"class file data {}\".format(data))\n",
    "        for line in data[1:]:\n",
    "            if type == \"maskrcnn\":\n",
    "                if \",\" not in line:\n",
    "                    continue\n",
    "                # slogger.glob.info(\"classes line {}\".format(line))\n",
    "                label, num = line.strip().split(',')\n",
    "                labels.append(('label', [('name', line.strip())]))\n",
    "            else:\n",
    "                if \"label\" not in line:\n",
    "                    labels.append(('label', [('name', line.strip())]))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "political-component",
   "metadata": {},
   "source": [
    "def main(args):\n",
    "    if args.type == \"both\":\n",
    "        od_model = ObjectDetection(args.od_model)\n",
    "        seg_model = Segmentation(args.mask_model)\n",
    "    elif args.type == \"classes\":\n",
    "        od_model = ObjectDetection(args.od_model)\n",
    "    elif args.type == \"v_shape\":\n",
    "        seg_model = Segmentation(args.mask_model)\n",
    "\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "    #would be better to take csv files as an input\n",
    "    #labels_mapping_od = {1:'dead', 2:'damaged',3:'healthy'}\n",
    "    labels_mapping_od = {1:'zero',2:'light',3:'medium',4:'high',5:'non_recoverable'}\n",
    "    frame_no = 0\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = math.ceil(cap.get(cv2.CAP_PROP_FPS))\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if args.num_frames == 'None' or args.num_frames == None:\n",
    "        args.num_frames = num_frames\n",
    "    #out = cv2.VideoWriter(os.path.basename(args.video)[:-4]+\"_skip_{}_numframes_{}.mp4\".format(args.skip_no, args.num_frames), fourcc, fps, (frame_width,frame_height))\n",
    "    # 'a' for annotation tacked onto end of filename\n",
    "    out = cv2.VideoWriter(f\"{args.output_dir}/{os.path.basename(args.video)[:-4]}a.mp4\", fourcc, fps, (frame_width,frame_height))\n",
    "\n",
    "    labels_from_csv = get_labels(args.classes_cvat, args.classes_type)\n",
    "    print(\"Labels: \", labels_from_csv)\n",
    "    final_result = {'meta':{'task': OrderedDict([('id',str(args.task_id)),('name',str(args.task_name)),('size',str(num_frames)),('mode','interpolation'),('start_frame', str(0)),('stop_frame', str(num_frames-1)),('z_order',\"False\"),('labels', labels_from_csv)])}, 'frames':[]}\n",
    "\n",
    "    #output_xml_path = \"cvat_annotation_\"+os.path.basename(args.video)[:-4]+\"_skip_{}_numframes_{}.xml\".format(args.skip_no, args.num_frames)\n",
    "    output_xml_path = f\"{args.output_dir}/{os.path.basename(args.video)[:-4]}.xml\"\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            if frame_no % args.skip_no != 0:\n",
    "                frame_no += 1\n",
    "                continue\n",
    "            print(\"Processing frame: \", frame_no)\n",
    "            # get image ready for inference\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image_org = Image.fromarray(img)\n",
    "            width, height = image_org.size\n",
    "            if width > 1920 or height > 1080:\n",
    "                image = image_org.resize((width // 2, height // 2), Image.ANTIALIAS)\n",
    "            else:\n",
    "                image = image_org\n",
    "            image_np = load_image_into_numpy(image)\n",
    "            image_mask_rcnn = load_image_into_numpy(image_org)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            od_result = {}\n",
    "            result = {}\n",
    "            if args.type == \"both\" or args.type == \"classes\":\n",
    "                # run detection\n",
    "                boxes, scores, classes, num_detections = od_model.get_detections(image_np_expanded)\n",
    "                #normalize bounding boxes, also apply threshold\n",
    "                od_result = ObjectDetection.process_boxes(boxes, scores, classes, labels_mapping_od, args.od_threshold, width, height)\n",
    "                if od_result:\n",
    "                    print(\"od\", od_result)\n",
    "                    shapes = []\n",
    "                    for label, boxes in od_result.items():\n",
    "                        for box in boxes:\n",
    "                            shapes.append({'type':'rectangle','label':label,'occluded':0,'points':box})\n",
    "                    final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "            if args.type == \"both\" or args.type == \"v_shape\":\n",
    "                # run segmentation\n",
    "                result = seg_model.get_polygons([image_mask_rcnn], args.mask_threshold)\n",
    "                print(\"Result without processing: \", result)\n",
    "                if args.type == \"both\" or args.type == \"classes\":\n",
    "                    # filter out false positives if boxes are available\n",
    "                    result = Segmentation.process_polygons(result, od_result)\n",
    "                print(\"Result: \", result)\n",
    "                if result:\n",
    "                    shapes = []\n",
    "                    for label, polygons in result.items():\n",
    "                        for polygon in polygons:\n",
    "                            shapes.append({'type':'polygon','label':label,'occluded':0,'points':polygon})\n",
    "                    frame_exists = False\n",
    "                    for frame_ in final_result['frames']:\n",
    "                        if frame_['frame'] == frame_no:\n",
    "                            break\n",
    "                    if frame_exists:\n",
    "                        final_result['frames']['shapes'].extend(shapes)\n",
    "                    else:\n",
    "                        final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "\n",
    "            frame = draw_instances(frame, od_result, result)\n",
    "            #write video\n",
    "            out.write(frame)\n",
    "\n",
    "            if (frame_no // args.skip_no) + 1 == int(args.num_frames):\n",
    "                dump_as_cvat_annotation(open(output_xml_path,\"w\"), final_result)\n",
    "                cap.release()\n",
    "                out.release()\n",
    "                break\n",
    "            frame_no += 1\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "\n",
    "                print(\"Final result: \", final_result)\n",
    "                dump_as_cvat_annotation(open(output_xml_path, \"w\"), final_result)\n",
    "                cap.release()\n",
    "                out.release()\n",
    "                break\n",
    "            except:  #handle case when video is corrupted or does not exists\n",
    "                break\n",
    "\n",
    "    return output_xml_path, args.num_frames"
   ]
  },
  {
   "cell_type": "raw",
   "id": "outdoor-balance",
   "metadata": {},
   "source": [
    "# aws s3 cp s3://cnas-re.uog.onepanel.io/raw-input/20200703/20200703_121802.geojson inference_data/\n",
    "# aws s3 cp s3://cnas-re.uog.onepanel.io/raw-input/20200703/20200703_121802.mp4 inference_data/\n",
    "# aws s3 cp s3://cnas-re.uog.onepanel.io/raw-input/20200703/20200703_121802_gps.csv inference_data/\n",
    "\n",
    "# python3 demo.py --num_frames 1000\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--type\",default=\"both\",help=\"what type of models to use [both,classes,v_shape]\")\n",
    "    parser.add_argument(\"--video\", default=\"inference_data/20200703_121802.mp4\", help=\"path to video\")\n",
    "    parser.add_argument(\"--gps_csv\", default=\"inference_data/20200703_121802_gps.csv\", help=\"path to csv containing gps data\")\n",
    "    parser.add_argument(\"--skip_no\", default=7, type=int, help=\"num of frames to skip\")\n",
    "    parser.add_argument(\"--num_frames\", default=None, help=\"how many frames to consider?\")\n",
    "    parser.add_argument(\"--od_model\", default=\"inference_data/frozen_inference_graph_5classes.pb\" , help=\"path to trained detection model\")\n",
    "    parser.add_argument(\"--classes_cvat\", default=\"inference_data/5classes.csv\", help=\"classes you want to use for cvat, see readme for more details.\")\n",
    "    parser.add_argument(\"--classes_type\", default=\"od\", help=\"type of classes csv file [od, maskrcnn]\")\n",
    "    parser.add_argument(\"--mask_model\", default=\"inference_data/mask_rcnn_cvat_0160.h5\", help=\"path to trained maskrcnn model\")\n",
    "    parser.add_argument(\"--od_threshold\",type=float, default=0.5, help=\"threshold for IoU\")\n",
    "    parser.add_argument(\"--mask_threshold\",type=float, default=0.5, help=\"threshold for maskrcnn\")\n",
    "    parser.add_argument(\"--output_video\", default=\"output.mp4\", help=\"where to store output video\")\n",
    "    parser.add_argument(\"--survey_type\", default=\"v_shape\",help=\"what to write in geojson [v_shape,classes\")\n",
    "    parser.add_argument(\"--task_id\", default=0, type=int, help=\"required only if you want to use this in cvat\")\n",
    "    parser.add_argument(\"--task_name\", default=\"demo\", help=\"requierd only if you want to use this in cvat\")\n",
    "    parser.add_argument(\"--write_into_objects\", default=True, help=\"should this enter detected objects into objects table?\")\n",
    "    parser.add_argument(\"--drop_extra_clm\", default=True, help=\"whether it should drop extra columns? required if dumping into objects table\")\n",
    "    parser.add_argument(\"--output_dir\", default='', help=\"output directory for video with objects detected and CVAT xml\")\n",
    "    # have to use string as we cant have condition statements in workflow\n",
    "    parser.add_argument('--dump_sql', default=True)\n",
    "    args = parser.parse_args()\n",
    "    if args.type not in ['both','classes','v_shape']:\n",
    "        raise ValueError('Invalid type: {}. Valid options are \"both\",\"classes\",\"v_shape\".'.format(args.type))\n",
    "    # if not os.path.exists(args.video):\n",
    "    #     raise FileExistsError(\"Video does not exist!\")\n",
    "    output_xml_path, num_frames_ = main(args)\n",
    "    if args.dump_sql == True or args.dump_sql == 'True':\n",
    "        dump_to_sql(output_xml_path, args.gps_csv, os.path.basename(args.video), args.skip_no, args.write_into_objects, args.drop_extra_clm, num_frames_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affected-converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aubrey/.local/lib/python3.6/site-packages/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aubrey/.local/lib/python3.6/site-packages/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/aubrey/.local/lib/python3.6/site-packages/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/aubrey/.local/lib/python3.6/site-packages/mrcnn/model.py:723: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aubrey/.local/lib/python3.6/site-packages/mrcnn/model.py:725: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aubrey/.local/lib/python3.6/site-packages/mrcnn/model.py:775: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Labels:  [('label', [('name', 'zero')]), ('label', [('name', 'light')]), ('label', [('name', 'medium')]), ('label', [('name', 'high')]), ('label', [('name', 'non_recoverable')])]\n",
      "Processing frame:  0\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  1\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  2\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  3\n",
      "od {'zero': [[3, 266, 371, 763]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  4\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  5\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  6\n",
      "od {'zero': [[7, 268, 366, 781]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  7\n",
      "od {'zero': [[0, 280, 384, 774]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  8\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  9\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  10\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  11\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  12\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  13\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  14\n",
      "od {'light': [[5, 292, 384, 764]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  15\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  16\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  17\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  18\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  19\n",
      "Result without processing:  {'cut': [[101.0, 416.5, 58.0, 416.5, 43.0, 409.5, 15.5, 406.0, 14.5, 314.0, 24.0, 310.5, 34.0, 315.5, 73.0, 295.5, 81.0, 298.5, 104.0, 294.5, 159.0, 294.5, 186.0, 301.5, 193.5, 319.0, 191.5, 393.0, 184.0, 401.5, 170.0, 407.5, 101.0, 416.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  20\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  21\n",
      "od {'light': [[0, 273, 401, 764]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  22\n",
      "od {'light': [[0, 278, 376, 755]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  23\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  24\n",
      "Result without processing:  {'cut': [[98.0, 414.5, 75.0, 414.5, 54.0, 408.5, 47.5, 397.0, 51.5, 374.0, 60.5, 360.0, 105.0, 318.5, 149.0, 301.5, 161.0, 292.5, 168.0, 293.5, 171.5, 340.0, 161.5, 378.0, 151.0, 390.5, 112.0, 411.5, 98.0, 414.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  25\n",
      "od {'light': [[0, 275, 367, 761]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  26\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  27\n",
      "od {'light': [[1411, 362, 1841, 803]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  28\n",
      "od {'light': [[1223, 394, 1603, 804]], 'zero': [[1210, 402, 1591, 805]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  29\n",
      "od {'light': [[1114, 419, 1482, 806]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  30\n",
      "od {'zero': [[1095, 451, 1420, 817], [0, 480, 209, 792]], 'light': [[1075, 454, 1422, 810]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  31\n",
      "od {'light': [[2, 476, 287, 862], [1075, 461, 1398, 790]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  32\n",
      "od {'light': [[0, 502, 361, 868], [1077, 486, 1380, 781]], 'zero': [[1082, 475, 1388, 787]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  33\n",
      "od {'light': [[14, 541, 550, 923], [1176, 482, 1458, 793]], 'zero': [[1183, 492, 1459, 787]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  34\n",
      "od {'light': [[232, 575, 737, 927], [1295, 527, 1576, 795]], 'zero': [[1290, 516, 1570, 802]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  35\n",
      "od {'zero': [[1470, 540, 1763, 823]], 'light': [[504, 602, 948, 955]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  36\n",
      "od {'light': [[0, 28, 409, 841], [693, 620, 1115, 952], [1629, 563, 1907, 855]], 'zero': [[698, 621, 1118, 956]]}\n",
      "Result without processing:  {'cut': [[214.0, 100.5, 170.0, 99.5, 143.5, 77.0, 143.5, 55.0, 153.5, 48.0, 163.0, 30.5, 204.0, 13.5, 257.0, 13.5, 317.0, 7.5, 332.5, 12.0, 337.5, 42.0, 333.5, 54.0, 324.0, 62.5, 300.0, 72.5, 268.0, 77.5, 230.0, 96.5, 214.0, 100.5], [1782.0, 684.5, 1765.0, 684.5, 1750.0, 677.5, 1716.5, 673.0, 1708.5, 642.0, 1680.5, 614.0, 1679.5, 567.0, 1683.0, 559.5, 1729.0, 563.5, 1744.0, 555.5, 1784.0, 553.5, 1823.5, 563.0, 1822.5, 622.0, 1812.5, 630.0, 1809.5, 643.0, 1816.5, 678.0, 1806.0, 683.5, 1802.0, 677.5, 1795.0, 677.5, 1782.0, 684.5]]}\n",
      "Result:  {'cut': [[214.0, 100.5, 170.0, 99.5, 143.5, 77.0, 143.5, 55.0, 153.5, 48.0, 163.0, 30.5, 204.0, 13.5, 257.0, 13.5, 317.0, 7.5, 332.5, 12.0, 337.5, 42.0, 333.5, 54.0, 324.0, 62.5, 300.0, 72.5, 268.0, 77.5, 230.0, 96.5, 214.0, 100.5], [1782.0, 684.5, 1765.0, 684.5, 1750.0, 677.5, 1716.5, 673.0, 1708.5, 642.0, 1680.5, 614.0, 1679.5, 567.0, 1683.0, 559.5, 1729.0, 563.5, 1744.0, 555.5, 1784.0, 553.5, 1823.5, 563.0, 1822.5, 622.0, 1812.5, 630.0, 1809.5, 643.0, 1816.5, 678.0, 1806.0, 683.5, 1802.0, 677.5, 1795.0, 677.5, 1782.0, 684.5]]}\n",
      "Processing frame:  37\n",
      "od {'light': [[856, 640, 1279, 950], [0, 0, 579, 986], [1758, 562, 1920, 819]]}\n",
      "Result without processing:  {'cut': [[361.0, 168.5, 333.0, 165.5, 326.5, 161.0, 319.5, 141.0, 323.5, 125.0, 352.0, 101.5, 364.0, 97.5, 410.0, 64.5, 448.0, 63.5, 458.0, 67.5, 459.5, 82.0, 451.5, 98.0, 439.0, 108.5, 400.0, 127.5, 382.5, 156.0, 361.0, 168.5]]}\n",
      "Result:  {'cut': [[361.0, 168.5, 333.0, 165.5, 326.5, 161.0, 319.5, 141.0, 323.5, 125.0, 352.0, 101.5, 364.0, 97.5, 410.0, 64.5, 448.0, 63.5, 458.0, 67.5, 459.5, 82.0, 451.5, 98.0, 439.0, 108.5, 400.0, 127.5, 382.5, 156.0, 361.0, 168.5]]}\n",
      "Processing frame:  38\n",
      "od {'light': [[41, 0, 682, 1024], [936, 642, 1362, 991]], 'zero': [[945, 649, 1362, 988]]}\n",
      "Result without processing:  {'cut': [[524.0, 172.5, 488.0, 169.5, 471.0, 159.5, 467.5, 150.0, 474.5, 129.0, 480.0, 122.5, 525.0, 105.5, 569.0, 103.5, 576.0, 106.5, 586.5, 130.0, 582.5, 149.0, 565.0, 161.5, 524.0, 172.5]]}\n",
      "Result:  {'cut': [[524.0, 172.5, 488.0, 169.5, 471.0, 159.5, 467.5, 150.0, 474.5, 129.0, 480.0, 122.5, 525.0, 105.5, 569.0, 103.5, 576.0, 106.5, 586.5, 130.0, 582.5, 149.0, 565.0, 161.5, 524.0, 172.5]]}\n",
      "Processing frame:  39\n",
      "od {'light': [[34, 0, 782, 1055], [1044, 640, 1456, 992]]}\n",
      "Result without processing:  {'cut': [[576.0, 237.5, 563.0, 236.5, 551.0, 230.5, 537.0, 214.5, 521.5, 205.0, 520.5, 190.0, 555.0, 172.5, 606.0, 158.5, 648.0, 160.5, 666.5, 174.0, 674.5, 197.0, 671.5, 212.0, 664.0, 222.5, 639.0, 232.5, 576.0, 237.5]]}\n",
      "Result:  {'cut': [[576.0, 237.5, 563.0, 236.5, 551.0, 230.5, 537.0, 214.5, 521.5, 205.0, 520.5, 190.0, 555.0, 172.5, 606.0, 158.5, 648.0, 160.5, 666.5, 174.0, 674.5, 197.0, 671.5, 212.0, 664.0, 222.5, 639.0, 232.5, 576.0, 237.5]]}\n",
      "Processing frame:  40\n",
      "od {'light': [[87, 0, 901, 1030]], 'zero': [[1161, 653, 1580, 992]]}\n",
      "Result without processing:  {'cut': [[682.0, 285.5, 670.0, 283.5, 649.5, 260.0, 634.5, 237.0, 639.5, 226.0, 697.0, 192.5, 737.0, 191.5, 761.0, 200.5, 767.5, 210.0, 768.5, 227.0, 758.5, 253.0, 738.0, 266.5, 682.0, 285.5], [856.0, 697.5, 834.0, 695.5, 813.0, 687.5, 794.5, 666.0, 791.5, 649.0, 803.0, 637.5, 834.0, 633.5, 866.0, 649.5, 882.5, 668.0, 892.5, 690.0, 888.0, 694.5, 856.0, 697.5]]}\n",
      "Result:  {'cut': [[682.0, 285.5, 670.0, 283.5, 649.5, 260.0, 634.5, 237.0, 639.5, 226.0, 697.0, 192.5, 737.0, 191.5, 761.0, 200.5, 767.5, 210.0, 768.5, 227.0, 758.5, 253.0, 738.0, 266.5, 682.0, 285.5], [856.0, 697.5, 834.0, 695.5, 813.0, 687.5, 794.5, 666.0, 791.5, 649.0, 803.0, 637.5, 834.0, 633.5, 866.0, 649.5, 882.5, 668.0, 892.5, 690.0, 888.0, 694.5, 856.0, 697.5]]}\n",
      "Processing frame:  41\n",
      "od {'light': [[1260, 639, 1671, 1010], [216, 50, 977, 1041]]}\n",
      "Result without processing:  {'cut': [[735.0, 297.5, 724.0, 296.5, 707.5, 278.0, 705.5, 269.0, 710.0, 261.5, 756.0, 229.5, 791.0, 213.5, 817.0, 212.5, 831.5, 223.0, 834.5, 236.0, 826.0, 249.5, 805.0, 261.5, 780.0, 269.5, 735.0, 297.5]]}\n",
      "Result:  {'cut': [[735.0, 297.5, 724.0, 296.5, 707.5, 278.0, 705.5, 269.0, 710.0, 261.5, 756.0, 229.5, 791.0, 213.5, 817.0, 212.5, 831.5, 223.0, 834.5, 236.0, 826.0, 249.5, 805.0, 261.5, 780.0, 269.5, 735.0, 297.5]]}\n",
      "Processing frame:  42\n",
      "od {'light': [[248, 38, 992, 1042], [1267, 637, 1686, 1014]], 'zero': [[1280, 640, 1685, 1012]]}\n",
      "Result without processing:  {'cut': [[807.0, 283.5, 767.0, 273.5, 747.5, 252.0, 746.5, 238.0, 754.0, 231.5, 799.0, 212.5, 846.0, 215.5, 860.5, 236.0, 856.5, 260.0, 839.0, 277.5, 807.0, 283.5]]}\n",
      "Result:  {'cut': [[807.0, 283.5, 767.0, 273.5, 747.5, 252.0, 746.5, 238.0, 754.0, 231.5, 799.0, 212.5, 846.0, 215.5, 860.5, 236.0, 856.5, 260.0, 839.0, 277.5, 807.0, 283.5]]}\n",
      "Processing frame:  43\n",
      "od {'light': [[1428, 606, 1910, 947]]}\n",
      "Result without processing:  {'cut': [[925.0, 254.5, 903.0, 249.5, 893.0, 240.5, 879.0, 239.5, 877.5, 227.0, 922.0, 204.5, 956.0, 179.5, 984.0, 178.5, 996.0, 181.5, 1005.5, 189.0, 1008.5, 198.0, 1006.5, 213.0, 1000.5, 228.0, 990.0, 237.5, 978.0, 243.5, 925.0, 254.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  44\n",
      "Result without processing:  {'cut': [[629.0, 667.5, 579.0, 665.5, 559.5, 655.0, 559.5, 635.0, 572.5, 607.0, 594.0, 588.5, 652.0, 566.5, 679.0, 544.5, 696.0, 540.5, 731.0, 542.5, 730.5, 566.0, 711.5, 603.0, 693.5, 626.0, 666.0, 652.5, 642.0, 665.5, 629.0, 667.5], [525.0, 573.5, 496.0, 573.5, 488.5, 568.0, 482.5, 548.0, 483.5, 521.0, 487.5, 513.0, 541.0, 481.5, 572.0, 475.5, 597.0, 477.5, 617.5, 504.0, 612.5, 530.0, 573.0, 545.5, 542.0, 567.5, 525.0, 573.5], [1798.0, 423.5, 1782.5, 421.0, 1803.5, 417.0, 1796.5, 414.0, 1795.5, 398.0, 1762.5, 360.0, 1763.5, 345.0, 1784.0, 331.5, 1809.0, 327.5, 1846.0, 327.5, 1860.0, 331.5, 1876.0, 342.5, 1889.5, 364.0, 1889.5, 401.0, 1867.0, 410.5, 1829.0, 412.5, 1798.0, 423.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  45\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  46\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  47\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  48\n",
      "Result without processing:  {'cut': [[1302.0, 704.5, 1253.0, 701.5, 1244.0, 696.5, 1239.5, 686.0, 1240.5, 660.0, 1235.5, 641.0, 1264.0, 620.5, 1309.0, 612.5, 1331.0, 612.5, 1339.5, 618.0, 1340.5, 629.0, 1346.5, 639.0, 1360.5, 643.0, 1362.5, 658.0, 1331.0, 693.5, 1302.0, 704.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  49\n",
      "Result without processing:  {'cut': [[1345.0, 709.5, 1291.0, 708.5, 1283.0, 704.5, 1279.5, 691.0, 1280.5, 668.0, 1285.5, 651.0, 1302.0, 634.5, 1365.0, 601.5, 1396.0, 598.5, 1397.0, 603.5, 1372.5, 607.0, 1381.5, 611.0, 1383.5, 628.0, 1392.5, 633.0, 1402.5, 649.0, 1402.5, 657.0, 1382.0, 692.5, 1345.0, 709.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  50\n",
      "Result without processing:  {'cut': [[1469.0, 585.5, 1447.0, 581.5, 1422.0, 566.5, 1410.5, 555.0, 1407.5, 534.0, 1411.5, 521.0, 1421.0, 511.5, 1435.0, 508.5, 1479.5, 525.0, 1483.5, 537.0, 1482.5, 579.0, 1478.0, 584.5, 1469.0, 585.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  51\n",
      "Result without processing:  {'cut': [[456.0, 834.5, 445.0, 832.5, 441.5, 828.0, 440.5, 793.0, 442.5, 776.0, 463.5, 738.0, 497.0, 701.5, 543.0, 667.5, 594.0, 608.5, 609.0, 595.5, 631.0, 593.5, 684.5, 620.0, 681.5, 655.0, 675.5, 667.0, 644.5, 712.0, 620.0, 736.5, 589.0, 758.5, 553.0, 774.5, 533.0, 790.5, 521.0, 793.5, 480.0, 830.5, 456.0, 834.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  52\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  53\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  54\n",
      "od {'light': [[1275, 8, 1920, 948]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  55\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  56\n",
      "od {'light': [[293, 730, 380, 787]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  57\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  58\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  59\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  60\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  61\n",
      "od {'light': [[33, 852, 275, 1039]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  62\n",
      "Result without processing:  {'cut': [[1108.0, 761.5, 1074.0, 753.5, 1055.0, 742.5, 1028.5, 712.0, 1021.5, 684.0, 998.5, 648.0, 968.5, 583.0, 985.5, 527.0, 992.0, 522.5, 1009.0, 525.5, 1053.0, 550.5, 1100.0, 547.5, 1114.0, 552.5, 1174.5, 630.0, 1183.5, 655.0, 1190.5, 695.0, 1190.5, 715.0, 1184.5, 732.0, 1174.0, 743.5, 1155.0, 753.5, 1108.0, 761.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  63\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  64\n",
      "od {'light': [[116, 633, 460, 958]]}\n",
      "Result without processing:  {'cut': [[247.0, 711.5, 234.0, 708.5, 212.5, 688.0, 207.5, 673.0, 210.0, 665.5, 235.0, 661.5, 259.5, 674.0, 265.5, 691.0, 247.0, 711.5], [145.0, 808.5, 118.0, 806.5, 110.5, 799.0, 110.5, 788.0, 119.0, 781.5, 134.0, 778.5, 172.0, 778.5, 177.5, 782.0, 177.0, 789.5, 145.0, 808.5]]}\n",
      "Result:  {'cut': [[247.0, 711.5, 234.0, 708.5, 212.5, 688.0, 207.5, 673.0, 210.0, 665.5, 235.0, 661.5, 259.5, 674.0, 265.5, 691.0, 247.0, 711.5], [145.0, 808.5, 118.0, 806.5, 110.5, 799.0, 110.5, 788.0, 119.0, 781.5, 134.0, 778.5, 172.0, 778.5, 177.5, 782.0, 177.0, 789.5, 145.0, 808.5]]}\n",
      "Processing frame:  65\n",
      "od {'light': [[316, 600, 679, 1046], [0, 523, 223, 945], [806, 705, 1040, 984]], 'zero': [[813, 705, 1040, 981]]}\n",
      "Result without processing:  {'cut': [[1769.0, 660.5, 1760.0, 660.5, 1753.5, 655.0, 1747.5, 633.0, 1749.0, 620.5, 1775.0, 624.5, 1790.0, 638.5, 1792.5, 637.0, 1789.5, 645.0, 1791.5, 654.0, 1769.0, 660.5], [178.0, 845.5, 166.0, 842.5, 114.0, 811.5, 109.5, 806.0, 110.5, 798.0, 135.0, 779.5, 149.0, 777.5, 184.5, 822.0, 187.5, 838.0, 184.0, 844.5, 178.0, 845.5], [1316.0, 707.5, 1313.0, 700.5, 1301.0, 702.5, 1288.0, 692.5, 1255.0, 694.5, 1249.5, 686.0, 1252.5, 670.0, 1266.0, 662.5, 1281.0, 662.5, 1295.0, 668.5, 1311.5, 679.0, 1317.5, 695.0, 1316.0, 707.5]]}\n",
      "Result:  {'cut': [[178.0, 845.5, 166.0, 842.5, 114.0, 811.5, 109.5, 806.0, 110.5, 798.0, 135.0, 779.5, 149.0, 777.5, 184.5, 822.0, 187.5, 838.0, 184.0, 844.5, 178.0, 845.5]]}\n",
      "Processing frame:  66\n",
      "od {'light': [[534, 508, 954, 1055], [0, 379, 507, 1012], [1001, 645, 1255, 933]]}\n",
      "Result without processing:  {'cut': [[483.0, 730.5, 438.0, 729.5, 431.0, 727.5, 419.5, 714.0, 419.5, 708.0, 437.5, 691.0, 433.5, 675.0, 443.5, 670.0, 439.5, 664.0, 461.0, 640.5, 487.0, 640.5, 513.5, 665.0, 512.0, 672.5, 506.0, 670.5, 487.0, 680.5, 479.0, 683.5, 474.0, 680.5, 470.5, 684.0, 502.5, 722.0, 498.0, 728.5, 483.0, 730.5]]}\n",
      "Result:  {'cut': [[483.0, 730.5, 438.0, 729.5, 431.0, 727.5, 419.5, 714.0, 419.5, 708.0, 437.5, 691.0, 433.5, 675.0, 443.5, 670.0, 439.5, 664.0, 461.0, 640.5, 487.0, 640.5, 513.5, 665.0, 512.0, 672.5, 506.0, 670.5, 487.0, 680.5, 479.0, 683.5, 474.0, 680.5, 470.5, 684.0, 502.5, 722.0, 498.0, 728.5, 483.0, 730.5]]}\n",
      "Processing frame:  67\n",
      "od {'light': [[338, 258, 936, 936], [928, 415, 1389, 1029], [1360, 562, 1673, 901]]}\n",
      "Result without processing:  {'cut': [[356.0, 690.5, 341.0, 690.5, 334.0, 686.5, 333.5, 669.0, 377.0, 628.5, 400.0, 617.5, 413.0, 616.5, 418.5, 629.0, 433.5, 646.0, 433.5, 657.0, 425.5, 675.0, 408.0, 684.5, 356.0, 690.5], [378.0, 620.5, 359.0, 619.5, 346.5, 612.0, 343.5, 580.0, 361.0, 561.5, 395.0, 554.5, 407.0, 542.5, 414.0, 540.5, 423.5, 556.0, 422.5, 569.0, 412.5, 579.0, 409.5, 599.0, 403.0, 606.5, 378.0, 620.5]]}\n",
      "Result:  {'cut': [[356.0, 690.5, 341.0, 690.5, 334.0, 686.5, 333.5, 669.0, 377.0, 628.5, 400.0, 617.5, 413.0, 616.5, 418.5, 629.0, 433.5, 646.0, 433.5, 657.0, 425.5, 675.0, 408.0, 684.5, 356.0, 690.5], [378.0, 620.5, 359.0, 619.5, 346.5, 612.0, 343.5, 580.0, 361.0, 561.5, 395.0, 554.5, 407.0, 542.5, 414.0, 540.5, 423.5, 556.0, 422.5, 569.0, 412.5, 579.0, 409.5, 599.0, 403.0, 606.5, 378.0, 620.5]]}\n",
      "Processing frame:  68\n",
      "od {'light': [[1029, 54, 1670, 1021]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  69\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  70\n",
      "Result without processing:  {'cut': [[1507.0, 228.5, 1474.0, 226.5, 1454.5, 209.0, 1455.5, 152.0, 1466.5, 128.0, 1541.5, 23.0, 1554.0, 13.5, 1576.0, 13.5, 1582.5, 18.0, 1590.5, 33.0, 1590.5, 73.0, 1579.5, 117.0, 1568.5, 190.0, 1562.5, 208.0, 1551.0, 218.5, 1532.0, 226.5, 1507.0, 228.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  71\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  72\n",
      "od {'zero': [[0, 580, 167, 813]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  73\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  74\n",
      "od {'light': [[238, 424, 659, 923]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  75\n",
      "od {'light': [[536, 353, 972, 1045]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  76\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  77\n",
      "Result without processing:  {'cut': [[289.0, 48.5, 285.5, 29.0, 276.5, 11.0, 281.0, 4.5, 330.0, 3.5, 366.0, 18.5, 372.0, 10.5, 375.5, 23.0, 379.5, 25.0, 364.0, 46.5, 360.0, 38.5, 337.0, 35.5, 324.0, 37.5, 321.0, 41.5, 300.0, 42.5, 305.5, 45.0, 289.0, 48.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  78\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  79\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  80\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  81\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  82\n",
      "Result without processing:  {'cut': [[341.0, 148.5, 316.0, 145.5, 293.5, 122.0, 278.5, 74.0, 279.5, 18.0, 282.5, 11.0, 289.0, 5.5, 327.0, 3.5, 418.0, 7.5, 426.5, 19.0, 426.5, 61.0, 421.5, 89.0, 391.0, 124.5, 365.0, 141.5, 341.0, 148.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  83\n",
      "od {'light': [[34, 23, 1191, 1028]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  84\n",
      "Result without processing:  {'cut': [[1889.0, 598.5, 1862.0, 589.5, 1853.0, 576.5, 1821.0, 560.5, 1789.0, 559.5, 1762.0, 569.5, 1735.0, 565.5, 1718.0, 558.5, 1708.0, 565.5, 1690.0, 559.5, 1680.5, 552.0, 1676.5, 540.0, 1679.5, 516.0, 1693.5, 505.0, 1713.5, 479.0, 1722.5, 454.0, 1720.5, 440.0, 1704.5, 415.0, 1706.0, 398.5, 1724.0, 394.5, 1753.0, 396.5, 1799.0, 428.5, 1863.0, 434.5, 1905.5, 454.0, 1911.5, 471.0, 1911.5, 571.0, 1903.5, 586.0, 1889.0, 598.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  85\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  86\n",
      "od {'zero': [[328, 829, 422, 987]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  87\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  88\n",
      "od {'light': [[1002, 393, 1612, 953]], 'zero': [[244, 815, 424, 1013], [355, 759, 603, 1002]]}\n",
      "Result without processing:  {'cut': [[1253.0, 444.5, 1235.5, 435.0, 1233.5, 421.0, 1249.0, 400.5, 1266.0, 399.5, 1273.5, 414.0, 1273.5, 423.0, 1253.0, 444.5], [1321.0, 465.5, 1297.0, 457.5, 1289.5, 436.0, 1300.5, 421.0, 1303.5, 407.0, 1313.0, 391.5, 1319.0, 390.5, 1328.0, 397.5, 1355.0, 392.5, 1363.5, 399.0, 1371.5, 417.0, 1376.5, 419.0, 1377.5, 428.0, 1340.0, 438.5, 1335.0, 435.5, 1330.5, 440.0, 1329.5, 457.0, 1321.0, 465.5]]}\n",
      "Result:  {'cut': [[1253.0, 444.5, 1235.5, 435.0, 1233.5, 421.0, 1249.0, 400.5, 1266.0, 399.5, 1273.5, 414.0, 1273.5, 423.0, 1253.0, 444.5], [1321.0, 465.5, 1297.0, 457.5, 1289.5, 436.0, 1300.5, 421.0, 1303.5, 407.0, 1313.0, 391.5, 1319.0, 390.5, 1328.0, 397.5, 1355.0, 392.5, 1363.5, 399.0, 1371.5, 417.0, 1376.5, 419.0, 1377.5, 428.0, 1340.0, 438.5, 1335.0, 435.5, 1330.5, 440.0, 1329.5, 457.0, 1321.0, 465.5]]}\n",
      "Processing frame:  89\n",
      "od {'zero': [[5, 697, 316, 1008]], 'light': [[1303, 206, 1919, 949]]}\n",
      "Result without processing:  {'cut': [[1766.0, 310.5, 1743.0, 307.5, 1730.0, 300.5, 1713.0, 297.5, 1705.5, 288.0, 1706.5, 277.0, 1714.5, 266.0, 1714.5, 244.0, 1724.5, 222.0, 1738.0, 213.5, 1775.0, 212.5, 1805.0, 217.5, 1815.5, 226.0, 1835.5, 256.0, 1834.5, 276.0, 1827.0, 288.5, 1790.0, 306.5, 1766.0, 310.5], [1372.0, 645.5, 1323.0, 643.5, 1307.5, 629.0, 1306.5, 613.0, 1340.5, 557.0, 1338.5, 553.0, 1351.0, 543.5, 1374.0, 540.5, 1413.0, 542.5, 1436.0, 548.5, 1448.5, 574.0, 1437.5, 607.0, 1427.0, 616.5, 1407.0, 623.5, 1385.0, 642.5, 1372.0, 645.5]]}\n",
      "Result:  {'cut': [[1766.0, 310.5, 1743.0, 307.5, 1730.0, 300.5, 1713.0, 297.5, 1705.5, 288.0, 1706.5, 277.0, 1714.5, 266.0, 1714.5, 244.0, 1724.5, 222.0, 1738.0, 213.5, 1775.0, 212.5, 1805.0, 217.5, 1815.5, 226.0, 1835.5, 256.0, 1834.5, 276.0, 1827.0, 288.5, 1790.0, 306.5, 1766.0, 310.5], [1372.0, 645.5, 1323.0, 643.5, 1307.5, 629.0, 1306.5, 613.0, 1340.5, 557.0, 1338.5, 553.0, 1351.0, 543.5, 1374.0, 540.5, 1413.0, 542.5, 1436.0, 548.5, 1448.5, 574.0, 1437.5, 607.0, 1427.0, 616.5, 1407.0, 623.5, 1385.0, 642.5, 1372.0, 645.5]]}\n",
      "Processing frame:  90\n",
      "od {'zero': [[0, 677, 281, 1009]]}\n",
      "Result without processing:  {'cut': [[730.0, 610.5, 713.5, 607.0, 715.0, 590.5, 727.0, 588.5, 737.5, 597.0, 736.5, 607.0, 730.0, 610.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  91\n",
      "od {'light': [[603, 553, 799, 877], [53, 583, 534, 1003]], 'zero': [[865, 524, 1081, 875]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  92\n",
      "od {'zero': [[1296, 406, 1606, 722], [323, 238, 1010, 1075], [20, 418, 585, 1076]], 'light': [[834, 341, 1483, 1019]]}\n",
      "Result without processing:  {'cut': [[1487.0, 768.5, 1473.0, 767.5, 1440.0, 753.5, 1431.5, 739.0, 1431.5, 715.0, 1434.0, 706.5, 1437.0, 721.5, 1445.0, 699.5, 1455.0, 698.5, 1469.0, 685.5, 1499.0, 678.5, 1515.5, 711.0, 1517.5, 741.0, 1509.0, 761.5, 1487.0, 768.5]]}\n",
      "Result:  {'cut': [[1487.0, 768.5, 1473.0, 767.5, 1440.0, 753.5, 1431.5, 739.0, 1431.5, 715.0, 1434.0, 706.5, 1437.0, 721.5, 1445.0, 699.5, 1455.0, 698.5, 1469.0, 685.5, 1499.0, 678.5, 1515.5, 711.0, 1517.5, 741.0, 1509.0, 761.5, 1487.0, 768.5]]}\n",
      "Processing frame:  93\n",
      "od {'light': [[648, 19, 1659, 1014]], 'zero': [[387, 497, 956, 1036]]}\n",
      "Result without processing:  {'cut': [[210.0, 365.5, 188.0, 364.5, 184.0, 357.5, 141.0, 342.5, 122.5, 327.0, 126.5, 297.0, 136.5, 282.0, 137.5, 264.0, 155.0, 248.5, 165.0, 245.5, 228.0, 248.5, 236.0, 252.5, 242.5, 262.0, 243.5, 272.0, 237.5, 293.0, 212.5, 359.0, 214.5, 364.0, 210.0, 365.5], [1680.0, 222.5, 1654.0, 220.5, 1636.0, 214.5, 1625.0, 208.5, 1613.5, 195.0, 1616.5, 116.0, 1628.5, 89.0, 1653.0, 63.5, 1716.0, 61.5, 1724.5, 68.0, 1733.5, 92.0, 1743.5, 159.0, 1738.5, 174.0, 1723.0, 196.5, 1703.0, 214.5, 1680.0, 222.5], [475.0, 351.5, 443.0, 351.5, 436.5, 337.0, 447.5, 314.0, 462.0, 302.5, 472.5, 304.0, 476.5, 323.0, 475.0, 351.5], [774.0, 218.5, 772.0, 213.5, 761.5, 209.0, 776.0, 204.5, 792.5, 210.0, 775.0, 212.5, 774.0, 218.5]]}\n",
      "Result:  {'cut': [[1680.0, 222.5, 1654.0, 220.5, 1636.0, 214.5, 1625.0, 208.5, 1613.5, 195.0, 1616.5, 116.0, 1628.5, 89.0, 1653.0, 63.5, 1716.0, 61.5, 1724.5, 68.0, 1733.5, 92.0, 1743.5, 159.0, 1738.5, 174.0, 1723.0, 196.5, 1703.0, 214.5, 1680.0, 222.5], [774.0, 218.5, 772.0, 213.5, 761.5, 209.0, 776.0, 204.5, 792.5, 210.0, 775.0, 212.5, 774.0, 218.5]]}\n",
      "Processing frame:  94\n",
      "od {'light': [[0, 3, 348, 963]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  95\n",
      "od {'light': [[943, 5, 1906, 874]]}\n",
      "Result without processing:  {'cut': [[1142.0, 252.5, 1133.0, 252.5, 1115.5, 239.0, 1106.5, 226.0, 1105.5, 215.0, 1152.0, 160.5, 1175.0, 144.5, 1186.0, 142.5, 1197.5, 154.0, 1196.5, 178.0, 1168.5, 233.0, 1142.0, 252.5]]}\n",
      "Result:  {'cut': [[1142.0, 252.5, 1133.0, 252.5, 1115.5, 239.0, 1106.5, 226.0, 1105.5, 215.0, 1152.0, 160.5, 1175.0, 144.5, 1186.0, 142.5, 1197.5, 154.0, 1196.5, 178.0, 1168.5, 233.0, 1142.0, 252.5]]}\n",
      "Processing frame:  96\n",
      "Result without processing:  {'cut': [[74.0, 935.5, 61.0, 933.5, 45.5, 920.0, 37.5, 894.0, 64.5, 830.0, 81.0, 818.5, 91.0, 818.5, 113.5, 831.0, 119.5, 848.0, 113.5, 874.0, 115.5, 925.0, 111.0, 932.5, 74.0, 935.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  97\n",
      "od {'zero': [[89, 215, 747, 1038], [918, 0, 1762, 947], [265, 38, 1220, 1059]]}\n",
      "Result without processing:  {'cut': [[193.0, 862.5, 174.0, 861.5, 168.5, 856.0, 182.5, 808.0, 209.5, 767.0, 244.0, 743.5, 248.0, 755.5, 264.5, 759.0, 272.5, 778.0, 271.5, 793.0, 240.5, 843.0, 231.0, 852.5, 193.0, 862.5]]}\n",
      "Result:  {'cut': [[193.0, 862.5, 174.0, 861.5, 168.5, 856.0, 182.5, 808.0, 209.5, 767.0, 244.0, 743.5, 248.0, 755.5, 264.5, 759.0, 272.5, 778.0, 271.5, 793.0, 240.5, 843.0, 231.0, 852.5, 193.0, 862.5]]}\n",
      "Processing frame:  98\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  99\n",
      "Result without processing:  {'cut': [[290.0, 114.5, 262.0, 112.5, 253.5, 103.0, 250.0, 82.5, 241.0, 84.5, 230.5, 93.0, 230.5, 103.0, 227.0, 106.5, 211.5, 106.0, 195.5, 68.0, 194.5, 49.0, 195.5, 29.0, 206.5, 25.0, 210.0, 6.5, 222.0, 9.5, 276.0, 4.5, 312.0, 5.5, 327.0, 12.5, 348.5, 34.0, 356.5, 58.0, 354.5, 103.0, 290.0, 114.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  100\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  101\n",
      "Result without processing:  {'cut': [[896.0, 477.5, 875.0, 475.5, 870.5, 471.0, 893.5, 429.0, 909.0, 410.5, 923.0, 402.5, 948.0, 407.5, 962.5, 431.0, 961.5, 442.0, 939.0, 463.5, 896.0, 477.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  102\n",
      "od {'light': [[0, 958, 80, 1066]], 'zero': [[1300, 420, 1816, 889]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  103\n",
      "od {'zero': [[1009, 752, 1199, 1018], [892, 742, 1076, 1026], [293, 929, 407, 1028]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  104\n",
      "od {'zero': [[1414, 704, 1621, 1001], [1546, 705, 1772, 999], [1690, 697, 1915, 994]]}\n",
      "Result without processing:  {'cut': [[1462.0, 751.5, 1429.0, 738.5, 1426.5, 729.0, 1429.5, 722.0, 1444.0, 718.5, 1472.0, 724.5, 1477.5, 742.0, 1462.0, 751.5]]}\n",
      "Result:  {'cut': [[1462.0, 751.5, 1429.0, 738.5, 1426.5, 729.0, 1429.5, 722.0, 1444.0, 718.5, 1472.0, 724.5, 1477.5, 742.0, 1462.0, 751.5]]}\n",
      "Processing frame:  105\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  106\n",
      "Result without processing:  {'cut': [[865.0, 769.5, 837.0, 768.5, 830.5, 765.0, 824.5, 752.0, 825.5, 707.0, 830.5, 687.0, 843.5, 662.0, 859.0, 653.5, 874.0, 657.5, 901.0, 673.5, 911.0, 672.5, 920.5, 680.0, 929.5, 696.0, 934.5, 733.0, 933.5, 746.0, 926.0, 755.5, 892.0, 766.5, 865.0, 769.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  107\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  108\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  109\n",
      "od {'light': [[7, 331, 493, 1010]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  110\n",
      "od {'light': [[11, 146, 787, 1080]]}\n",
      "Result without processing:  {'cut': [[164.0, 310.5, 153.0, 309.5, 147.5, 303.0, 150.5, 293.0, 124.5, 260.0, 112.5, 230.0, 111.5, 204.0, 116.5, 193.0, 140.0, 176.5, 156.0, 177.5, 166.0, 182.5, 184.5, 200.0, 203.5, 238.0, 212.5, 277.0, 210.0, 307.5, 178.0, 304.5, 164.0, 310.5]]}\n",
      "Result:  {'cut': [[164.0, 310.5, 153.0, 309.5, 147.5, 303.0, 150.5, 293.0, 124.5, 260.0, 112.5, 230.0, 111.5, 204.0, 116.5, 193.0, 140.0, 176.5, 156.0, 177.5, 166.0, 182.5, 184.5, 200.0, 203.5, 238.0, 212.5, 277.0, 210.0, 307.5, 178.0, 304.5, 164.0, 310.5]]}\n",
      "Processing frame:  111\n",
      "od {'light': [[6, 225, 351, 896]]}\n",
      "Result without processing:  {'cut': [[0.0, 184.5, 6.0, 175.5, 21.0, 171.5, 48.0, 176.5, 62.5, 194.0, 73.5, 221.0, 83.5, 229.0, 91.5, 256.0, 87.5, 263.0, 88.5, 281.0, 82.5, 286.0, 78.5, 300.0, 64.0, 307.5, 33.0, 305.5, 6.5, 283.0, 0.0, 267.5]]}\n",
      "Result:  {'cut': [[0.0, 184.5, 6.0, 175.5, 21.0, 171.5, 48.0, 176.5, 62.5, 194.0, 73.5, 221.0, 83.5, 229.0, 91.5, 256.0, 87.5, 263.0, 88.5, 281.0, 82.5, 286.0, 78.5, 300.0, 64.0, 307.5, 33.0, 305.5, 6.5, 283.0, 0.0, 267.5]]}\n",
      "Processing frame:  112\n",
      "Result without processing:  {'cut': [[1087.0, 412.5, 1053.0, 407.5, 1017.0, 407.5, 994.5, 394.0, 986.5, 369.0, 994.5, 350.0, 994.5, 336.0, 1014.0, 311.5, 1030.0, 307.5, 1044.0, 311.5, 1096.5, 313.0, 1094.5, 316.0, 1099.5, 321.0, 1085.0, 324.5, 1081.5, 332.0, 1086.5, 353.0, 1084.5, 394.0, 1088.0, 402.5, 1098.5, 406.0, 1097.0, 410.5, 1087.0, 412.5], [647.5, 0.0, 667.0, 4.5, 678.0, 11.5, 688.5, 30.0, 692.5, 43.0, 692.5, 96.0, 686.5, 110.0, 677.0, 120.5, 657.0, 125.5, 653.5, 131.0, 655.5, 138.0, 652.0, 140.5, 645.0, 135.5, 640.0, 139.5, 613.0, 142.5, 603.0, 151.5, 548.0, 155.5, 537.5, 149.0, 532.5, 134.0, 530.5, 97.0, 526.5, 87.0, 530.5, 58.0, 523.5, 38.0, 522.5, 21.0, 534.0, 6.5, 550.0, 0.5, 609.5, 0.0]]}\n",
      "Result:  {}\n",
      "Processing frame:  113\n",
      "Result without processing:  {'cut': [[853.0, 753.5, 759.0, 733.5, 757.5, 701.0, 799.0, 679.5, 833.0, 672.5, 856.0, 673.5, 888.0, 685.5, 904.5, 699.0, 914.5, 714.0, 919.5, 732.0, 917.5, 742.0, 910.0, 746.5, 853.0, 753.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  114\n",
      "od {'light': [[13, 6, 751, 983]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  115\n",
      "od {'light': [[29, 818, 323, 1065]]}\n",
      "Result without processing:  {'cut': [[1693.0, 523.5, 1679.0, 523.5, 1669.0, 513.5, 1645.0, 501.5, 1597.0, 486.5, 1578.5, 474.0, 1573.5, 447.0, 1576.5, 400.0, 1580.5, 390.0, 1597.0, 375.5, 1616.0, 374.5, 1647.0, 384.5, 1680.0, 402.5, 1700.0, 418.5, 1740.0, 437.5, 1754.5, 453.0, 1756.5, 474.0, 1744.5, 491.0, 1717.0, 514.5, 1693.0, 523.5], [93.0, 273.5, 80.5, 269.0, 77.0, 255.5, 34.5, 241.0, 29.5, 235.0, 32.5, 226.0, 21.5, 204.0, 23.5, 194.0, 65.0, 166.5, 106.0, 148.5, 159.0, 144.5, 178.0, 149.5, 186.5, 173.0, 180.5, 206.0, 135.0, 254.5, 104.0, 271.5, 93.0, 273.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  116\n",
      "od {'light': [[3, 63, 500, 955], [748, 784, 1145, 1080]]}\n",
      "Result without processing:  {'cut': [[536.0, 559.5, 523.5, 559.0, 520.5, 516.0, 531.0, 498.5, 550.0, 490.5, 560.0, 493.5, 575.5, 512.0, 582.5, 529.0, 582.5, 544.0, 575.0, 553.5, 536.0, 559.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  117\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  118\n",
      "od {'light': [[0, 589, 232, 952]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  119\n",
      "od {'light': [[7, 470, 646, 1080]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  120\n",
      "od {'light': [[922, 153, 1845, 1080]]}\n",
      "Result without processing:  {'cut': [[1095.0, 511.5, 1071.0, 509.5, 1047.0, 482.5, 1024.0, 472.5, 1019.5, 464.0, 1020.5, 450.0, 1033.5, 426.0, 1034.5, 402.0, 1038.5, 392.0, 1063.0, 380.5, 1101.0, 380.5, 1121.0, 385.5, 1129.5, 393.0, 1139.5, 424.0, 1142.5, 440.0, 1139.5, 467.0, 1120.0, 473.5, 1105.5, 487.0, 1105.5, 500.0, 1117.5, 505.0, 1095.0, 511.5], [705.0, 684.5, 661.0, 668.5, 652.5, 658.0, 648.5, 644.0, 652.5, 594.0, 662.0, 576.5, 674.0, 585.5, 690.0, 590.5, 701.5, 607.0, 715.5, 618.0, 731.5, 642.0, 731.5, 657.0, 720.5, 664.0, 713.5, 679.0, 705.0, 684.5], [1482.0, 527.5, 1474.0, 527.5, 1456.0, 516.5, 1445.0, 516.5, 1430.5, 500.0, 1448.5, 445.0, 1503.0, 386.5, 1522.0, 386.5, 1555.0, 394.5, 1560.5, 403.0, 1558.5, 413.0, 1543.5, 435.0, 1532.5, 472.0, 1502.5, 516.0, 1482.0, 527.5]]}\n",
      "Result:  {'cut': [[1095.0, 511.5, 1071.0, 509.5, 1047.0, 482.5, 1024.0, 472.5, 1019.5, 464.0, 1020.5, 450.0, 1033.5, 426.0, 1034.5, 402.0, 1038.5, 392.0, 1063.0, 380.5, 1101.0, 380.5, 1121.0, 385.5, 1129.5, 393.0, 1139.5, 424.0, 1142.5, 440.0, 1139.5, 467.0, 1120.0, 473.5, 1105.5, 487.0, 1105.5, 500.0, 1117.5, 505.0, 1095.0, 511.5], [1482.0, 527.5, 1474.0, 527.5, 1456.0, 516.5, 1445.0, 516.5, 1430.5, 500.0, 1448.5, 445.0, 1503.0, 386.5, 1522.0, 386.5, 1555.0, 394.5, 1560.5, 403.0, 1558.5, 413.0, 1543.5, 435.0, 1532.5, 472.0, 1502.5, 516.0, 1482.0, 527.5]]}\n",
      "Processing frame:  121\n",
      "od {'light': [[1106, 594, 1790, 1075]]}\n",
      "Result without processing:  {'cut': [[1441.0, 663.5, 1431.0, 662.5, 1415.5, 650.0, 1406.5, 633.0, 1401.5, 608.0, 1409.0, 596.5, 1431.0, 580.5, 1463.0, 573.5, 1492.5, 589.0, 1503.5, 604.0, 1504.5, 621.0, 1500.5, 632.0, 1487.0, 644.5, 1482.0, 642.5, 1463.0, 648.5, 1441.0, 663.5], [1820.0, 708.5, 1802.0, 708.5, 1794.5, 704.0, 1783.5, 668.0, 1765.5, 631.0, 1759.5, 604.0, 1761.5, 582.0, 1771.0, 569.5, 1808.0, 557.5, 1829.0, 563.5, 1838.5, 572.0, 1847.5, 625.0, 1843.5, 657.0, 1823.5, 692.0, 1832.5, 700.0, 1820.0, 708.5]]}\n",
      "Result:  {'cut': [[1441.0, 663.5, 1431.0, 662.5, 1415.5, 650.0, 1406.5, 633.0, 1401.5, 608.0, 1409.0, 596.5, 1431.0, 580.5, 1463.0, 573.5, 1492.5, 589.0, 1503.5, 604.0, 1504.5, 621.0, 1500.5, 632.0, 1487.0, 644.5, 1482.0, 642.5, 1463.0, 648.5, 1441.0, 663.5], [1820.0, 708.5, 1802.0, 708.5, 1794.5, 704.0, 1783.5, 668.0, 1765.5, 631.0, 1759.5, 604.0, 1761.5, 582.0, 1771.0, 569.5, 1808.0, 557.5, 1829.0, 563.5, 1838.5, 572.0, 1847.5, 625.0, 1843.5, 657.0, 1823.5, 692.0, 1832.5, 700.0, 1820.0, 708.5]]}\n",
      "Processing frame:  122\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  123\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  124\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  125\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  126\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  127\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  128\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  129\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  130\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  131\n",
      "Result without processing:  {'cut': [[117.0, 380.5, 102.0, 380.5, 94.0, 376.5, 81.5, 362.0, 79.5, 352.0, 87.5, 340.0, 87.5, 321.0, 117.0, 291.5, 143.0, 279.5, 161.0, 280.5, 168.5, 285.0, 172.5, 298.0, 172.5, 333.0, 140.0, 372.5, 117.0, 380.5], [272.0, 491.5, 264.0, 491.5, 245.0, 482.5, 190.5, 447.0, 185.5, 429.0, 203.0, 394.5, 219.0, 394.5, 237.0, 401.5, 287.5, 448.0, 291.5, 461.0, 289.5, 475.0, 272.0, 491.5], [348.0, 522.5, 322.0, 520.5, 311.0, 514.5, 296.5, 502.0, 297.5, 484.0, 354.0, 453.5, 382.0, 451.5, 386.5, 455.0, 381.5, 459.0, 388.5, 469.0, 388.5, 484.0, 366.0, 511.5, 348.0, 522.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  132\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  133\n",
      "Result without processing:  {'cut': [[430.0, 289.5, 401.0, 289.5, 396.5, 285.0, 381.5, 201.0, 389.5, 135.0, 415.0, 109.5, 436.0, 116.5, 465.0, 136.5, 478.5, 152.0, 488.5, 177.0, 495.5, 240.0, 493.5, 263.0, 484.0, 277.5, 451.0, 288.5, 430.0, 289.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  134\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  135\n",
      "od {'light': [[349, 911, 496, 1020], [146, 882, 303, 1019]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  136\n",
      "od {'light': [[928, 889, 1087, 1014]], 'zero': [[46, 848, 254, 1003], [206, 848, 386, 1005]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  137\n",
      "od {'light': [[1069, 861, 1236, 1003], [890, 843, 1039, 976]], 'zero': [[140, 838, 369, 1021]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  138\n",
      "od {'light': [[956, 836, 1139, 977]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  139\n",
      "od {'zero': [[0, 745, 268, 1035], [235, 808, 452, 1008]], 'light': [[934, 813, 1123, 964]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  140\n",
      "od {'zero': [[797, 749, 1014, 952], [991, 790, 1214, 968], [237, 778, 529, 1043], [0, 686, 273, 1039]], 'light': [[223, 778, 534, 1044], [0, 676, 286, 1050]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  141\n",
      "od {'zero': [[421, 736, 749, 1037], [715, 806, 904, 1018], [970, 695, 1215, 1007]], 'light': [[1170, 756, 1417, 1011]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  142\n",
      "od {'zero': [[1041, 741, 1262, 1026], [421, 494, 884, 1048], [1181, 633, 1550, 1006], [0, 442, 648, 1008], [782, 670, 1092, 1028]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  143\n",
      "od {'zero': [[0, 707, 214, 1068]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  144\n",
      "od {'light': [[919, 29, 1920, 1061]]}\n",
      "Result without processing:  {'cut': [[802.0, 792.5, 785.5, 788.0, 782.5, 780.0, 762.5, 762.0, 751.5, 736.0, 749.5, 702.0, 758.0, 691.5, 779.0, 677.5, 798.5, 679.0, 816.5, 706.0, 832.5, 719.0, 838.5, 743.0, 838.5, 767.0, 833.5, 785.0, 826.0, 789.5, 802.0, 792.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  145\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  146\n",
      "od {'light': [[689, 61, 1707, 1078], [12, 653, 179, 800], [128, 568, 350, 842]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  147\n",
      "od {'light': [[1262, 242, 1920, 1068]], 'zero': [[0, 477, 199, 779]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  148\n",
      "od {'light': [[973, 371, 1270, 760]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  149\n",
      "od {'light': [[1082, 325, 1558, 840]]}\n",
      "Result without processing:  {'cut': [[1563.0, 323.5, 1556.0, 323.5, 1531.5, 297.0, 1519.5, 269.0, 1497.5, 254.0, 1493.5, 245.0, 1495.0, 219.5, 1555.0, 219.5, 1567.5, 233.0, 1570.5, 246.0, 1568.5, 269.0, 1595.5, 292.0, 1596.5, 298.0, 1594.0, 303.5, 1576.0, 311.5, 1563.0, 323.5], [1160.0, 511.5, 1115.0, 505.5, 1100.5, 485.0, 1101.5, 478.0, 1121.0, 459.5, 1137.0, 458.5, 1149.0, 463.5, 1166.0, 475.5, 1180.5, 493.0, 1179.0, 504.5, 1160.0, 511.5]]}\n",
      "Result:  {'cut': [[1160.0, 511.5, 1115.0, 505.5, 1100.5, 485.0, 1101.5, 478.0, 1121.0, 459.5, 1137.0, 458.5, 1149.0, 463.5, 1166.0, 475.5, 1180.5, 493.0, 1179.0, 504.5, 1160.0, 511.5]]}\n",
      "Processing frame:  150\n",
      "od {'light': [[1291, 208, 1903, 858]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  151\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  152\n",
      "Result without processing:  {'cut': [[1066.0, 289.5, 1059.5, 282.0, 1053.5, 255.0, 1060.5, 235.0, 1084.0, 215.5, 1107.0, 209.5, 1118.0, 211.5, 1125.5, 219.0, 1129.5, 238.0, 1125.5, 261.0, 1110.0, 273.5, 1084.0, 283.5, 1071.0, 282.5, 1066.0, 289.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  153\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  154\n",
      "Result without processing:  {'cut': [[1248.0, 146.5, 1237.5, 141.0, 1249.0, 135.5, 1251.5, 142.0, 1248.0, 146.5], [1687.0, 453.5, 1674.5, 441.0, 1675.5, 389.0, 1702.0, 356.5, 1714.0, 351.5, 1725.0, 352.5, 1744.5, 384.0, 1741.5, 420.0, 1720.0, 447.5, 1701.0, 444.5, 1687.0, 453.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  155\n",
      "Result without processing:  {'cut': [[43.0, 613.5, 17.0, 610.5, 8.5, 601.0, 2.5, 581.0, 15.5, 546.0, 31.5, 525.0, 60.0, 500.5, 88.0, 492.5, 128.0, 492.5, 145.0, 496.5, 166.0, 506.5, 208.5, 544.0, 208.5, 555.0, 190.0, 584.5, 183.0, 583.5, 174.0, 588.5, 167.0, 581.5, 150.0, 585.5, 132.0, 580.5, 111.0, 580.5, 72.0, 606.5, 43.0, 613.5], [1411.0, 476.5, 1402.0, 475.5, 1400.0, 470.5, 1376.5, 462.0, 1374.5, 452.0, 1386.5, 432.0, 1405.0, 421.5, 1450.0, 415.5, 1469.0, 417.5, 1472.5, 430.0, 1458.5, 453.0, 1442.0, 464.5, 1411.0, 476.5], [220.0, 510.5, 198.0, 503.5, 182.5, 485.0, 180.5, 467.0, 194.5, 455.0, 198.0, 446.5, 220.5, 449.0, 220.5, 459.0, 232.5, 494.0, 228.5, 504.0, 220.0, 510.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  156\n",
      "od {'light': [[1616, 653, 1913, 992]]}\n",
      "Result without processing:  {'cut': [[441.0, 629.5, 425.0, 629.5, 416.5, 625.0, 425.5, 606.0, 417.5, 585.0, 431.5, 560.0, 425.5, 529.0, 433.0, 526.5, 451.0, 527.5, 459.0, 533.5, 483.0, 539.5, 487.5, 555.0, 500.5, 576.0, 499.5, 594.0, 491.0, 611.5, 451.0, 619.5, 457.5, 624.0, 441.0, 629.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  157\n",
      "od {'light': [[1609, 662, 1911, 981]]}\n",
      "Result without processing:  {'cut': [[462.0, 622.5, 433.0, 618.5, 422.5, 612.0, 429.5, 608.0, 431.5, 598.0, 429.5, 576.0, 443.5, 555.0, 444.5, 544.0, 440.5, 540.0, 444.5, 535.0, 439.5, 528.0, 438.5, 517.0, 446.0, 509.5, 457.5, 516.0, 472.0, 544.5, 484.0, 542.5, 492.5, 548.0, 501.5, 567.0, 500.5, 587.0, 489.5, 608.0, 480.0, 616.5, 462.0, 622.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  158\n",
      "Result without processing:  {'cut': [[1073.0, 364.5, 1020.0, 363.5, 962.0, 347.5, 941.5, 331.0, 930.5, 314.0, 928.5, 283.0, 956.0, 267.5, 1013.0, 245.5, 1073.0, 239.5, 1103.0, 246.5, 1132.0, 263.5, 1141.0, 274.5, 1154.0, 276.5, 1162.0, 273.5, 1185.5, 288.0, 1193.5, 316.0, 1192.5, 323.0, 1185.0, 330.5, 1130.0, 357.5, 1110.0, 356.5, 1073.0, 364.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  159\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  160\n",
      "od {'light': [[1623, 647, 1912, 987]]}\n",
      "Result without processing:  {'cut': [[475.0, 617.5, 466.0, 617.5, 454.5, 599.0, 453.5, 590.0, 458.5, 588.0, 458.5, 583.0, 453.5, 582.0, 452.5, 575.0, 454.0, 566.5, 458.5, 573.0, 467.5, 530.0, 483.0, 522.5, 491.5, 528.0, 495.0, 537.5, 499.0, 532.5, 511.5, 533.0, 520.5, 548.0, 526.5, 574.0, 524.5, 582.0, 499.0, 606.5, 475.0, 617.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  161\n",
      "od {'light': [[1631, 643, 1912, 1004]]}\n",
      "Result without processing:  {'cut': [[467.0, 617.5, 456.0, 616.5, 453.5, 613.0, 463.0, 609.5, 463.5, 605.0, 456.5, 601.0, 455.5, 589.0, 450.5, 585.0, 472.5, 529.0, 489.0, 526.5, 500.0, 539.5, 511.5, 546.0, 520.5, 564.0, 525.5, 564.0, 526.5, 581.0, 500.0, 605.5, 467.0, 617.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  162\n",
      "Result without processing:  {'cut': [[481.0, 622.5, 465.0, 621.5, 459.5, 606.0, 463.5, 601.0, 461.5, 570.0, 468.5, 563.0, 471.5, 541.0, 480.5, 534.0, 475.5, 530.0, 484.0, 527.5, 490.5, 530.0, 486.0, 534.5, 505.5, 545.0, 517.5, 585.0, 507.5, 609.0, 481.0, 622.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  163\n",
      "od {'light': [[1638, 640, 1917, 992]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  164\n",
      "Result without processing:  {'cut': [[1789.0, 687.5, 1766.0, 685.5, 1758.5, 675.0, 1761.5, 662.0, 1776.0, 659.5, 1791.0, 668.5, 1797.5, 682.0, 1789.0, 687.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  165\n",
      "od {'light': [[1629, 664, 1910, 963]]}\n",
      "Result without processing:  {'cut': [[1789.0, 687.5, 1776.0, 686.5, 1762.0, 679.5, 1759.5, 671.0, 1762.5, 663.0, 1778.0, 659.5, 1790.0, 667.5, 1795.5, 674.0, 1796.5, 683.0, 1789.0, 687.5]]}\n",
      "Result:  {'cut': [[1789.0, 687.5, 1776.0, 686.5, 1762.0, 679.5, 1759.5, 671.0, 1762.5, 663.0, 1778.0, 659.5, 1790.0, 667.5, 1795.5, 674.0, 1796.5, 683.0, 1789.0, 687.5]]}\n",
      "Processing frame:  166\n",
      "od {'light': [[1639, 655, 1913, 977]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  167\n",
      "od {'light': [[1637, 649, 1917, 996]]}\n",
      "Result without processing:  {'cut': [[1025.0, 332.5, 998.0, 331.5, 992.5, 328.0, 993.0, 322.5, 977.5, 314.0, 970.5, 296.0, 968.5, 269.0, 971.5, 251.0, 978.5, 239.0, 1021.0, 208.5, 1042.0, 201.5, 1090.0, 201.5, 1119.0, 196.5, 1193.0, 198.5, 1231.0, 209.5, 1239.5, 217.0, 1242.5, 232.0, 1236.5, 246.0, 1206.0, 267.5, 1112.0, 305.5, 1098.0, 318.5, 1073.0, 321.5, 1067.0, 329.5, 1059.0, 331.5, 1036.0, 329.5, 1025.0, 332.5], [1793.0, 687.5, 1781.0, 684.5, 1769.5, 676.0, 1767.0, 658.5, 1789.0, 664.5, 1801.5, 674.0, 1800.5, 683.0, 1793.0, 687.5], [487.0, 618.5, 467.0, 616.5, 458.5, 600.0, 457.5, 570.0, 471.5, 541.0, 478.0, 536.5, 503.0, 545.5, 523.5, 576.0, 522.5, 590.0, 517.5, 591.0, 497.0, 616.5, 487.0, 618.5]]}\n",
      "Result:  {'cut': [[1793.0, 687.5, 1781.0, 684.5, 1769.5, 676.0, 1767.0, 658.5, 1789.0, 664.5, 1801.5, 674.0, 1800.5, 683.0, 1793.0, 687.5]]}\n",
      "Processing frame:  168\n",
      "od {'light': [[1637, 649, 1910, 988]]}\n",
      "Result without processing:  {'cut': [[1094.0, 342.5, 1013.0, 332.5, 1003.5, 315.0, 992.5, 311.0, 983.5, 288.0, 982.5, 260.0, 990.5, 244.0, 1009.0, 228.5, 1027.0, 220.5, 1077.0, 206.5, 1098.0, 204.5, 1118.0, 204.5, 1142.0, 226.5, 1175.0, 239.5, 1181.5, 251.0, 1194.5, 262.0, 1188.5, 267.0, 1188.5, 276.0, 1170.0, 282.5, 1169.0, 289.5, 1157.0, 291.5, 1151.0, 299.5, 1129.0, 304.5, 1113.5, 327.0, 1114.5, 333.0, 1094.0, 342.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  169\n",
      "od {'light': [[1633, 651, 1911, 969]]}\n",
      "Result without processing:  {'cut': [[459.0, 619.5, 446.0, 618.5, 442.5, 614.0, 452.5, 601.0, 446.5, 591.0, 450.5, 569.0, 465.0, 539.5, 479.0, 537.5, 499.0, 544.5, 522.0, 567.5, 526.5, 566.0, 526.5, 584.0, 503.0, 605.5, 459.0, 619.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  170\n",
      "od {'light': [[1630, 647, 1915, 996]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  171\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  172\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  173\n",
      "Result without processing:  {'cut': [[443.0, 621.5, 431.0, 620.5, 428.5, 608.0, 432.0, 604.5, 443.0, 605.5, 447.5, 601.0, 436.5, 588.0, 461.5, 542.0, 451.5, 531.0, 453.5, 522.0, 459.0, 513.5, 483.0, 517.5, 469.0, 521.5, 476.5, 526.0, 469.0, 527.5, 466.5, 533.0, 485.0, 542.5, 504.0, 539.5, 521.5, 561.0, 521.5, 575.0, 493.0, 608.5, 474.0, 617.5, 443.0, 621.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  174\n",
      "Result without processing:  {'cut': [[1791.0, 679.5, 1778.0, 679.5, 1765.0, 672.5, 1758.5, 665.0, 1761.5, 657.0, 1774.0, 656.5, 1793.0, 667.5, 1795.5, 676.0, 1791.0, 679.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  175\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  176\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  177\n",
      "od {'light': [[1624, 675, 1908, 979]]}\n",
      "Result without processing:  {'cut': [[470.0, 615.5, 458.0, 615.5, 463.5, 610.0, 457.5, 593.0, 441.5, 589.0, 444.5, 586.0, 441.5, 582.0, 447.5, 577.0, 446.5, 563.0, 453.5, 529.0, 458.0, 521.5, 464.0, 520.5, 487.5, 526.0, 482.5, 532.0, 491.0, 539.5, 494.5, 537.0, 510.5, 572.0, 506.5, 585.0, 495.5, 599.0, 470.0, 615.5], [1521.0, 437.5, 1490.0, 429.5, 1486.5, 422.0, 1504.0, 405.5, 1524.0, 402.5, 1530.5, 423.0, 1521.0, 437.5]]}\n",
      "Result:  {}\n",
      "Processing frame:  178\n",
      "od {'light': [[1621, 684, 1913, 974]]}\n",
      "Result without processing:  {}\n",
      "Result:  {}\n",
      "Processing frame:  179\n",
      "Result without processing:  {'cut': [[464.0, 608.5, 456.0, 608.5, 443.0, 598.5, 440.0, 602.5, 437.5, 597.0, 440.0, 587.5, 441.5, 595.0, 445.5, 594.0, 444.5, 583.0, 439.5, 579.0, 449.5, 557.0, 451.5, 531.0, 458.0, 513.5, 479.0, 515.5, 478.5, 519.0, 494.5, 533.0, 495.5, 551.0, 503.5, 574.0, 496.5, 590.0, 482.0, 603.5, 464.0, 608.5]]}\n",
      "Result:  {}\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "if type == \"both\":\n",
    "    od_model = ObjectDetection(od_model)\n",
    "    seg_model = Segmentation(mask_model)\n",
    "elif type == \"classes\":\n",
    "    od_model = ObjectDetection(od_model)\n",
    "elif type == \"v_shape\":\n",
    "    seg_model = Segmentation(mask_model)\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "#would be better to take csv files as an input\n",
    "#labels_mapping_od = {1:'dead', 2:'damaged',3:'healthy'}\n",
    "labels_mapping_od = {1:'zero',2:'light',3:'medium',4:'high',5:'non_recoverable'}\n",
    "frame_no = 0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = math.ceil(cap.get(cv2.CAP_PROP_FPS))\n",
    "num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "if num_frames == 'None' or num_frames == None:\n",
    "    num_frames = num_frames\n",
    "#out = cv2.VideoWriter(os.path.basename(video)[:-4]+\"_skip_{}_numframes_{}.mp4\".format(skip_no, num_frames), fourcc, fps, (frame_width,frame_height))\n",
    "# 'a' for annotation tacked onto end of filename\n",
    "out = cv2.VideoWriter(f\"{output_dir}/{os.path.basename(video)[:-4]}a.mp4\", fourcc, fps, (frame_width,frame_height))\n",
    "\n",
    "labels_from_csv = get_labels(classes_cvat, classes_type)\n",
    "print(\"Labels: \", labels_from_csv)\n",
    "final_result = {'meta':{'task': OrderedDict([('id',str(task_id)),('name',str(task_name)),('size',str(num_frames)),('mode','interpolation'),('start_frame', str(0)),('stop_frame', str(num_frames-1)),('z_order',\"False\"),\n",
    "                                             ('labels', labels_from_csv)])}, 'frames':[]}\n",
    "\n",
    "#output_xml_path = \"cvat_annotation_\"+os.path.basename(video)[:-4]+\"_skip_{}_numframes_{}.xml\".format(skip_no, num_frames)\n",
    "output_xml_path = f\"{output_dir}/{os.path.basename(video)[:-4]}.xml\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if frame_no % skip_no != 0:\n",
    "            frame_no += 1\n",
    "            continue\n",
    "        print(\"Processing frame: \", frame_no)\n",
    "        # get image ready for inference\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image_org = Image.fromarray(img)\n",
    "        width, height = image_org.size\n",
    "        if width > 1920 or height > 1080:\n",
    "            image = image_org.resize((width // 2, height // 2), Image.ANTIALIAS)\n",
    "        else:\n",
    "            image = image_org\n",
    "        image_np = load_image_into_numpy(image)\n",
    "        image_mask_rcnn = load_image_into_numpy(image_org)\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "        od_result = {}\n",
    "        result = {}\n",
    "        if type == \"both\" or type == \"classes\":\n",
    "            # run detection\n",
    "            boxes, scores, classes, num_detections = od_model.get_detections(image_np_expanded)\n",
    "            #normalize bounding boxes, also apply threshold\n",
    "            od_result = ObjectDetection.process_boxes(boxes, scores, classes, labels_mapping_od, od_threshold, width, height)\n",
    "            if od_result:\n",
    "                print(\"od\", od_result)\n",
    "                shapes = []\n",
    "                for label, boxes in od_result.items():\n",
    "                    for box in boxes:\n",
    "                        shapes.append({'type':'rectangle','label':label,'occluded':0,'points':box})\n",
    "                final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "        if type == \"both\" or type == \"v_shape\":\n",
    "            # run segmentation\n",
    "            result = seg_model.get_polygons([image_mask_rcnn], mask_threshold)\n",
    "            print(\"Result without processing: \", result)\n",
    "            if type == \"both\" or type == \"classes\":\n",
    "                # filter out false positives if boxes are available\n",
    "                result = Segmentation.process_polygons(result, od_result)\n",
    "            print(\"Result: \", result)\n",
    "            if result:\n",
    "                shapes = []\n",
    "                for label, polygons in result.items():\n",
    "                    for polygon in polygons:\n",
    "                        shapes.append({'type':'polygon','label':label,'occluded':0,'points':polygon})\n",
    "                frame_exists = False\n",
    "                for frame_ in final_result['frames']:\n",
    "                    if frame_['frame'] == frame_no:\n",
    "                        break\n",
    "                if frame_exists:\n",
    "                    final_result['frames']['shapes'].extend(shapes)\n",
    "                else:\n",
    "                    final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "\n",
    "        frame = draw_instances(frame, od_result, result)\n",
    "        #write video\n",
    "        out.write(frame)\n",
    "\n",
    "        if (frame_no // skip_no) + 1 == int(num_frames):\n",
    "            dump_as_cvat_annotation(open(output_xml_path,\"w\"), final_result)\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            break\n",
    "        frame_no += 1\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "\n",
    "            print(\"Final result: \", final_result)\n",
    "            dump_as_cvat_annotation(open(output_xml_path, \"w\"), final_result)\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            break\n",
    "        except:  #handle case when video is corrupted or does not exists\n",
    "            break\n",
    "\n",
    "#    return output_xml_path, num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerical-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "print('FINISHED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
