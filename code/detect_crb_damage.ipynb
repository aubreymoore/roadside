{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-advertiser",
   "metadata": {},
   "source": [
    "# detect_crb_damage.ipynb\n",
    "\n",
    "* 2021-05-02 First version by Aubrey Moore\n",
    "\n",
    "This notebook uses a pair of Tensorflow object detectors to measure coconut rhinoceros beetle damage in digital images.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "    papermill detect_crb_damage.ipynb \\\n",
    "     '../open-camera-test/home-uog/detect_crb_damage_output.ipynb' \\\n",
    "    -p IMAGE_FILE_PATH '../open-camera-test/home-uog/*.jpg' \\\n",
    "    -p OUTPUT_XML_PATH '../open-camera-test/home-uog/detected_objects.xml'\n",
    "\n",
    "When the above command line is executed in the directory containing **detect_crb_damage.ipynb**, \n",
    "all **jpg** image files in the **../open-camera-test/home-uog** directory will be scanned by the\n",
    "object detectors and results will be saved in **../open-camera-test/home-uog/detected_objects.xml**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fresh-arrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# import tensorflow as tf\n",
    "# uncomment following lines if you are using TF2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import cv2\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('./Mask_RCNN')\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "import skimage.io\n",
    "from collections import OrderedDict\n",
    "from skimage.measure import find_contours, approximate_polygon\n",
    "from xml_dumper import dump_as_cvat_annotation\n",
    "import glob\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "asian-douglas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sought-surveillance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 145 Âµs (started: 2021-05-06 09:29:38 +10:00)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advance-hybrid",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.3 ms (started: 2021-05-06 09:29:38 +10:00)\n"
     ]
    }
   ],
   "source": [
    "# Run from the roadside/code directory:\n",
    "\n",
    "IMAGE_FILE_PATH = '../open-camera-test/home-uog/*.jpg'                  # Path to one or more image files. Can include wildcards. See https://pymotw.com/2/glob/ for pattern matching details.\n",
    "OUTPUT_XML_PATH = '../open-camera-test/home-uog/detected-objects.xml'   # Path to output file which will contain metadata for detected objects.\n",
    "TYPE = 'both'                                                  # what type of models to use [both,classes,v_shape]\n",
    "#SKIP_NO = 1                                                    # int, num of frames to skip (must be >0)\n",
    "#NUM_FRAMES = None                                              # how many frames to consider?\n",
    "OD_MODEL = \"inference_data/frozen_inference_graph_5classes.pb\" # path to trained detection model\n",
    "CLASSES_CVAT = \"inference_data/5classes.csv\"                   # classes you want to use for cvat, see readme for more details.\n",
    "CLASSES_TYPE = \"od\"                                            # type of classes csv file [od, maskrcnn]\n",
    "MASK_MODEL =  \"inference_data/mask_rcnn_cvat_0160.h5\"          # path to trained maskrcnn model\n",
    "OD_THRESHOLD = 0.5                                             # threshold for IoU\n",
    "MASK_THRESHOLD = 0.5                                           # threshold for maskrcnn\n",
    "#SURVEY_TYPE = \"v_shape\"                                        # what to write in geojson [v_shape,classes]\n",
    "TASK_ID = 0                                                    # required only if you want to use this in cvat\n",
    "TASK_NAME = \"demo\"                                             # required only if you want to use this in cvat\n",
    "DUMP_SQL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "challenging-monitoring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.35 ms (started: 2021-05-06 09:29:38 +10:00)\n"
     ]
    }
   ],
   "source": [
    "class ObjectDetection:\n",
    "    def __init__(self, model_path):\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(model_path , 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "                config = tf.ConfigProto()\n",
    "                config.gpu_options.allow_growth=True\n",
    "                self.sess = tf.Session(graph=self.detection_graph, config=config)\n",
    "\n",
    "    def get_detections(self, image_np_expanded):\n",
    "        image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        (boxes, scores, classes, num_detections) = self.sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n",
    "        return boxes, scores, classes, num_detections\n",
    "\n",
    "    @staticmethod\n",
    "    def process_boxes(boxes, scores, classes, labels_mapping, threshold, width, height):\n",
    "        result = {}\n",
    "        for i in range(len(classes[0])):\n",
    "            if classes[0][i] in labels_mapping.keys():\n",
    "                if scores[0][i] >= threshold:\n",
    "                    xmin = int(boxes[0][i][1] * width)\n",
    "                    ymin = int(boxes[0][i][0] * height)\n",
    "                    xmax = int(boxes[0][i][3] * width)\n",
    "                    ymax = int(boxes[0][i][2] * height)\n",
    "                    label = labels_mapping[classes[0][i]]\n",
    "                    if label not in result:\n",
    "                        result[label] = []\n",
    "                    result[label].append([xmin,ymin,xmax,ymax])\n",
    "        return result\n",
    "\n",
    "class Segmentation:\n",
    "    def __init__(self, model_path, num_c=2):\n",
    "        class InferenceConfig(Config):\n",
    "            # Set batch size to 1 since we'll be running inference on\n",
    "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "            NAME = \"cvat\"\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "            NUM_CLASSES = num_c\n",
    "\n",
    "        config = InferenceConfig()\n",
    "        #config.display()\n",
    "\n",
    "        # Create model object in inference mode.\n",
    "        self.model = modellib.MaskRCNN(mode=\"inference\", model_dir=\"./output\", config=config)\n",
    "        # Load weights trained on MS-COCO\n",
    "        self.model.load_weights(model_path, by_name=True)\n",
    "        self.labels_mapping = {0:'BG', 1:'cut'}\n",
    "\n",
    "    def get_polygons(self, images, threshold):\n",
    "        res = self.model.detect(images)\n",
    "        result = {}\n",
    "        for r in res:\n",
    "            for index, c_id in enumerate(r['class_ids']):\n",
    "                if c_id in self.labels_mapping.keys():\n",
    "                    if r['scores'][index] >= threshold:\n",
    "                        mask = r['masks'][:,:,index].astype(np.uint8)\n",
    "                        contours = find_contours(mask, 0.5)\n",
    "\n",
    "                        # KLUDGE\n",
    "                        # Handles a rare \"list index out of range error\" for contours[0]\n",
    "                        # If the contours array is empty, a dummy contour consisting of\n",
    "                        # the top left pisxel is provided.\n",
    "\n",
    "                        if not contours:\n",
    "                            print('ERROR: contour list is empty.')\n",
    "                            contour = np.array([[1.0,1.0],[1.0,0.0],[0.0,0.0],[0.0,1.0],[1.0,1.0]])\n",
    "                        else:\n",
    "                            contour = contours[0]\n",
    "                            # print(f'contour ({type(contour)}): {contour}')\n",
    "\n",
    "                        # end of KLUDGE\n",
    "\n",
    "                        contour = np.flip(contour, axis=1)\n",
    "                        contour = approximate_polygon(contour, tolerance=2.5)\n",
    "                        segmentation = contour.ravel().tolist()\n",
    "                        label = self.labels_mapping[c_id]\n",
    "                        if label not in result:\n",
    "                            result[label] = []\n",
    "                        result[label].append(segmentation)\n",
    "        return result\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def process_polygons(polygons, boxes):\n",
    "        \"\"\"\n",
    "           Check if any point of the polygon falls into any of coconot palms except for dead/non_recoverable.\n",
    "        \"\"\"\n",
    "        def _check_inside_boxes(polygon, boxes):\n",
    "            for point in polygon:\n",
    "                for label, bxes in boxes.items():\n",
    "                    for box in bxes:\n",
    "                        if point[0] > box[0] and point[0] < box[2] and point[1] > box[1] and point[1] < box[3] and label not in ['dead','non_recoverable']:\n",
    "                            # point is inside rectangle\n",
    "                            return True\n",
    "            return False\n",
    "\n",
    "        result = {}\n",
    "        for label_m, polys in polygons.items():\n",
    "            for polygon in polys:\n",
    "                p = [polygon[i:i+2] for i in range(0, len(polygon),2)]\n",
    "                if _check_inside_boxes(p, boxes):\n",
    "                    if label_m not in result:\n",
    "                        result[label_m] = []\n",
    "                    result[label_m].append(polygon)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def load_image_into_numpy(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def draw_instances(frame, boxes, masks):\n",
    "    colors = {'zero':(0,255,0), 'light':(0,0,255),'medium':(255,0,0),'high':(120,120,0),'non_recoverable':(0,120,120),'cut':(0,0,0)}\n",
    "    #draw boxes\n",
    "    for label, bxes in boxes.items():\n",
    "        for box in bxes:\n",
    "            cv2.rectangle(frame, (box[0],box[1]), (box[2],box[3]), colors[label], 5)\n",
    "    #draw polygons\n",
    "    for label, polygons in masks.items():\n",
    "        for polygon in polygons:\n",
    "            p = [polygon[i:i+2] for i in range(0, len(polygon),2)]\n",
    "            pts = np.array(p, np.int32)\n",
    "            pts = pts.reshape((-1,1,2))\n",
    "            cv2.polylines(frame, [pts], True, (0,255,255),5)\n",
    "    return frame\n",
    "\n",
    "def get_labels(classes_csv, type=\"od\"):\n",
    "    labels = []\n",
    "    with open(classes_csv, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "        # slogger.glob.info(\"class file data {}\".format(data))\n",
    "        for line in data[1:]:\n",
    "            if type == \"maskrcnn\":\n",
    "                if \",\" not in line:\n",
    "                    continue\n",
    "                # slogger.glob.info(\"classes line {}\".format(line))\n",
    "                label, num = line.strip().split(',')\n",
    "                labels.append(('label', [('name', line.strip())]))\n",
    "            else:\n",
    "                if \"label\" not in line:\n",
    "                    labels.append(('label', [('name', line.strip())]))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "technological-commissioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-06T09:30:48+1000 [INFO] <module> Starting georef.py\n",
      "2021-05-06T09:31:39+1000 [INFO] <module> Image 100 of 1069\n",
      "2021-05-06T09:32:20+1000 [INFO] <module> Image 200 of 1069\n",
      "2021-05-06T09:33:02+1000 [INFO] <module> Image 300 of 1069\n",
      "2021-05-06T09:33:44+1000 [INFO] <module> Image 400 of 1069\n",
      "2021-05-06T09:34:28+1000 [INFO] <module> Image 500 of 1069\n",
      "2021-05-06T09:35:13+1000 [INFO] <module> Image 600 of 1069\n",
      "2021-05-06T09:35:58+1000 [INFO] <module> Image 700 of 1069\n",
      "2021-05-06T09:36:47+1000 [INFO] <module> Image 800 of 1069\n",
      "2021-05-06T09:37:32+1000 [INFO] <module> Image 900 of 1069\n",
      "2021-05-06T09:38:15+1000 [INFO] <module> Image 1000 of 1069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n",
      "time: 7min 56s (started: 2021-05-06 09:30:48 +10:00)\n"
     ]
    }
   ],
   "source": [
    "# NEW CODE\n",
    "\n",
    "# Initialization\n",
    "################\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(funcName)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%dT%H:%M:%S%z\",\n",
    "    handlers=[logging.StreamHandler()])\n",
    "logging.info('Starting georef.py')\n",
    "\n",
    "\n",
    "# Get a sorted list of image files\n",
    "\n",
    "# Intialize other variables\n",
    "\n",
    "image_files = sorted(glob.glob(IMAGE_FILE_PATH))\n",
    "num_frames = len(image_files)\n",
    "\n",
    "labels_from_csv = get_labels(CLASSES_CVAT, CLASSES_TYPE)\n",
    "final_result = {'meta':{'task': OrderedDict([('id',str(TASK_ID)),\n",
    "                                             ('name',str(TASK_NAME)),\n",
    "                                             ('size',str(num_frames)),\n",
    "                                             ('mode','interpolation'),\n",
    "                                             ('start_frame', str(0)),\n",
    "                                             ('stop_frame', str(num_frames-1)),\n",
    "                                             ('z_order',\"False\"),\n",
    "                                             ('labels', labels_from_csv)])},\n",
    "                'frames':[]}\n",
    "\n",
    "if TYPE == \"both\":\n",
    "    od_model = ObjectDetection(OD_MODEL)\n",
    "    seg_model = Segmentation(MASK_MODEL)\n",
    "elif TYPE == \"classes\":\n",
    "    od_model = ObjectDetection(OD_MODEL)\n",
    "elif TYPE == \"v_shape\":\n",
    "    seg_model = Segmentation(MASK_MODEL)\n",
    "    \n",
    "labels_mapping_od = {1:'zero',2:'light',3:'medium',4:'high',5:'non_recoverable'}\n",
    "\n",
    "# Get size of first image in list. It is assumed that all images are the same size.\n",
    "\n",
    "frame = cv2.imread(image_files[0])\n",
    "frame_height, frame_width, channels = frame.shape\n",
    "\n",
    "height, width = frame_height, frame_width\n",
    "\n",
    "# Process image files\n",
    "#####################\n",
    "\n",
    "frame_no = 0\n",
    "for image_file in image_files:\n",
    "    frame_no += 1\n",
    "    #print(f'Image {frame_no} of {num_frames}')\n",
    "    frame = cv2.imread(image_file)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image_np_expanded = np.expand_dims(img, axis=0)\n",
    "\n",
    "    od_result = {}\n",
    "    result = {}\n",
    "    if TYPE == \"both\" or TYPE == \"classes\":\n",
    "        # run detection\n",
    "        boxes, scores, classes, num_detections = od_model.get_detections(image_np_expanded)\n",
    "        #normalize bounding boxes, also apply threshold\n",
    "        od_result = ObjectDetection.process_boxes(boxes, scores, classes, labels_mapping_od, OD_THRESHOLD, width, height)\n",
    "        if od_result:\n",
    "            #print(\"od\", od_result)\n",
    "            shapes = []\n",
    "            for label, boxes in od_result.items():\n",
    "                for box in boxes:\n",
    "                    shapes.append({'type':'rectangle','label':label,'occluded':0,'points':box})\n",
    "            final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "    if TYPE == \"both\" or TYPE == \"v_shape\":\n",
    "        # run segmentation\n",
    "        result = seg_model.get_polygons([img], MASK_THRESHOLD)\n",
    "        #print(\"Result before processing: \", result)\n",
    "        if TYPE == \"both\" or TYPE == \"classes\":\n",
    "            # filter out false positives if boxes are available\n",
    "            result = Segmentation.process_polygons(result, od_result)\n",
    "            #print(\"Result after processing: \", result)\n",
    "        if result:\n",
    "            shapes = []\n",
    "            for label, polygons in result.items():\n",
    "                for polygon in polygons:\n",
    "                    shapes.append({'type':'polygon','label':label,'occluded':0,'points':polygon})\n",
    "            frame_exists = False\n",
    "            for frame_ in final_result['frames']:\n",
    "                if frame_['frame'] == frame_no:\n",
    "                    break\n",
    "            if frame_exists:\n",
    "                final_result['frames']['shapes'].extend(shapes)\n",
    "            else:\n",
    "                final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "        if (frame_no % 100 == 0):\n",
    "            logging.info(f'Image {frame_no} of {num_frames}')\n",
    "                        \n",
    "#frame = draw_instances(frame, od_result, result)\n",
    "dump_as_cvat_annotation(open(OUTPUT_XML_PATH, \"w\"), final_result)\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-coach",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
